"""
main.py
â”€â”€â”€â”€â”€â”€â”€
Pipeline centralisÃ© pour tester toutes les combinaisons :
(imputation + modÃ¨le), Ã©valuer les performances et sauvegarder
les rÃ©sultats + modÃ¨les + visualisations.

Chaque module (imputation, modÃ¨le, mÃ©triques, visualisation)
est isolÃ© et ne fait quâ€™une seule tÃ¢che.

Structure prÃ©vue :
- splitter.py : gÃ©nÃ¨re les splits train/test
- knn.py / mice.py / median.py : gÃ©nÃ¨rent les fichiers imputÃ©s
- random_forest.py / dnn.py / grandient_boost.py : entraÃ®nent les modÃ¨les
- metrics.py : calcule les scores
- visualizations.py : gÃ©nÃ¨re les graphiques comparatifs
"""

import os
import pandas as pd
from pathlib import Path
import joblib

# Chargement des modules (chaque module ne fait quâ€™une chose)
from utils.splitter import split_data
from imputation.knn import knn_impute
from imputation.mice import mice_impute
from imputation.median import median_impute

from models.random_forest import train_rf
from models.dnn import train_dnn
from models.grandient_boost import train_gb

from utils.metrics import calculate_metrics
from utils.visualizations import generate_all_plots

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. CONFIGURATION GLOBALE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

DATASET_NAME = "hta_nhanes_complet_variables_fr"

# Combinaisons Ã  tester
imputation_methods = ["knn", "mice", "median"]
model_functions = {
    "random_forest": train_rf,
    "dnn": train_dnn,
    "gradient_boost": train_gb
}

# RÃ©pertoires de travail
DATA_SPLIT_DIR = Path(f"data/splits/{DATASET_NAME}")
PROCESSED_DIR = Path(f"data/processed/{DATASET_NAME}")
RESULTS_DIR = Path("results/tables") / DATASET_NAME
MODELS_DIR = Path("models") / DATASET_NAME

# CrÃ©ation des dossiers au besoin
for d in [RESULTS_DIR, MODELS_DIR]:
    d.mkdir(parents=True, exist_ok=True)

# RÃ©cupÃ©rateur de toutes les mÃ©triques
all_results = []

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. SPLIT DU DATASET BRUT SI NON FAIT
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if not (DATA_SPLIT_DIR / f"{DATASET_NAME}_train.csv").exists():
    print(f"ğŸ“ Split du dataset {DATASET_NAME} ...")
    split_dataset(DATASET_NAME)
else:
    print(f"âœ… Splits dÃ©jÃ  prÃ©sents pour {DATASET_NAME}")



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. TRAITEMENT DE CHAQUE COMBINAISON
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

for imputation_method in imputation_methods:
    print(f"\nğŸ§© Ã‰tape dâ€™imputation : {imputation_method}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Imputation
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if imputation_method == "knn":
        knn_impute(DATASET_NAME)
    elif imputation_method == "mice":
        mice_impute(DATASET_NAME)
    elif imputation_method == "median":
        median_impute(DATASET_NAME)
    else:
        print(f"âŒ MÃ©thode dâ€™imputation inconnue : {imputation_method}")
        continue

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Chargement des donnÃ©es imputÃ©es
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    train_path = PROCESSED_DIR / f"{DATASET_NAME}_{imputation_method}_imputed_train.csv"
    test_path = PROCESSED_DIR / f"{DATASET_NAME}_{imputation_method}_imputed_test.csv"

    train_df = pd.read_csv(train_path)
    test_df = pd.read_csv(test_path)

    X_train = train_df.drop(columns=["HTA"])
    y_train = train_df["HTA"]
    X_test = test_df.drop(columns=["HTA"])
    y_test = test_df["HTA"]

    for model_name, model_func in model_functions.items():
        print(f"\nğŸš€ EntraÃ®nement du modÃ¨le : {model_name.upper()} avec {imputation_method.upper()}")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # EntraÃ®nement du modÃ¨le
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        model = model_func(X_train, y_train)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # PrÃ©dictions
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        y_pred = model.predict(X_test)
        y_proba = None
        if hasattr(model, "predict_proba"):
            try:
                y_proba = model.predict_proba(X_test)[:, 1]
            except:
                pass  # certains modÃ¨les n'ont pas .predict_proba()

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Ã‰valuation
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        result_df = calculate_metrics(
            y_true=y_test,
            y_pred=y_pred,
            y_proba=y_proba,
            nom_modele=model_name,
            nom_imputation=imputation_method
        )

        # Ajout au tableau final
        all_results.append(result_df)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Sauvegarde du modÃ¨le
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        model_out_dir = MODELS_DIR / f"{model_name}_{imputation_method}"
        model_out_dir.mkdir(parents=True, exist_ok=True)

        model_file = model_out_dir / "pipeline.joblib"
        joblib.dump(model, model_file)

        print(f"ğŸ’¾ ModÃ¨le enregistrÃ© : {model_file}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. COMPILATION DES MÃ‰TRIQUES
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

print("\nğŸ“Š Compilation des rÃ©sultats...")
final_results_df = pd.concat(all_results, ignore_index=True)

# Sauvegarde en CSV
metrics_path = RESULTS_DIR / f"{DATASET_NAME}_all_metrics.csv"
final_results_df.to_csv(metrics_path, index=False)
print(f"ğŸ“„ RÃ©sultats enregistrÃ©s dans : {metrics_path}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. GÃ‰NÃ‰RATION DES VISUALISATIONS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

try:
    print("ğŸ“ˆ GÃ©nÃ©ration des visualisations...")
    generate_all_plots(final_results_df, output_dir=RESULTS_DIR)
    print("âœ… Visualisations sauvegardÃ©es dans :", RESULTS_DIR)
except Exception as e:
    print("âŒ Ã‰chec lors de la gÃ©nÃ©ration des visualisations :", e)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. RÃ‰CAPITULATIF DU PIPELINE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

print("\nğŸ§¾ RÃ©sumÃ© du pipeline exÃ©cutÃ© :")
print(f"  â¤ Dataset analysÃ©      : {DATASET_NAME}")
print(f"  â¤ MÃ©thodes dâ€™imputation: {', '.join(imputation_methods)}")
print(f"  â¤ ModÃ¨les testÃ©s       : {', '.join(model_functions.keys())}")
print(f"  â¤ MÃ©triques disponibles : {metrics_path.name}")
print(f"  â¤ ModÃ¨les sauvegardÃ©s   : {MODELS_DIR}")
print(f"  â¤ Visualisations        : {RESULTS_DIR}")

print("\nğŸ‰ Pipeline terminÃ© avec succÃ¨s !\n")
